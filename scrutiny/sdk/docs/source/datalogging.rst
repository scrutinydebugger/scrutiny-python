.. _page_datalogging:

Datalogging
===========

Usage of the SDK watchables as described in :ref:`Accessing variables<page_accessing_variables>` is done through polling and the update rate is limited by the bandwidth 
of the communication link between the server and the device (Serial, TCP, CAN, etc). Therefore, monitoring a value in Python is not a reliable way to catch a 
fast event in the firmware since two polling events may be spaced by several milliseconds.

Datalogging (or `Embedded Graphs`) solve that problem by requesting the device to record a certain set of watchable in a circular buffer until a certain event occurs. 
It effectively transform the embedded device into a scope. 

The condition that stop the circular acquisition is called the `Trigger condition` and may be of many type.
Once the trigger condition is fulfilled, the acquisition finishes (immediately or after a specified amount of time) and the data is returned to the server to be saved into a database. 
A client can then download and display that data under the form of a graph.


Configuring the datalogger
--------------------------

The first step before configuring the datalogger is knowing what the device is capable of in terms of datalogging. We need information such as :

- Is datalogging even supported?
- What are the sampling rates?
- What is the size of the buffer?
- How many signal can I log?
- etc

Getting that information is done through :meth:`ScrutinyClient.get_datalogging_capabilities<scrutiny.sdk.client.ScrutinyClient.get_datalogging_capabilities>` 
and returns a :class:`DataloggingCapabilities<scrutiny.sdk.datalogging.DataloggingCapabilities>`

.. automethod:: scrutiny.sdk.client.ScrutinyClient.get_datalogging_capabilities

-----

.. autoclass:: scrutiny.sdk.datalogging.DataloggingCapabilities
    :exclude-members: __init__, __new__
    :members:

-----

Configuring and arming the datalogger is possible with the :meth:`ScrutinyClient.start_datalog<scrutiny.sdk.client.ScrutinyClient.start_datalog>` method
which takes a :class:`sdk.DataloggingConfig<scrutiny.sdk.datalogging.DataloggingConfig>` as sole argument. 

.. automethod:: scrutiny.sdk.client.ScrutinyClient.start_datalog

.. autoclass:: scrutiny.sdk.datalogging.DataloggingConfig
    :members:
    :exclude-members: __new__


-----

.. autoclass:: scrutiny.sdk.datalogging.TriggerCondition
    :members:
    :exclude-members: __init__, __new__

-----

.. autoclass:: scrutiny.sdk.datalogging.XAxisType
    :members:
    :exclude-members: __init__, __new__

-----

.. autoclass:: scrutiny.sdk.datalogging.AxisDefinition
    :members:
    :exclude-members: __init__, __new__

-----

.. autoclass:: scrutiny.sdk.datalogging.SamplingRate
    :members:
    :exclude-members: __init__, __new__

-----

.. autoclass:: scrutiny.sdk.datalogging.DataloggingRequest
    :members:
    :member-order: bysource
    :exclude-members: __init__, __new__

-----

Example
#######

.. code-block:: python

    with client.connect(hostname, port):
        var1 = client.watch('/a/b/var1')
        var2 = client.watch('/a/b/var2')

        config = sdk.datalogging.DataloggingConfig(sampling_rate=0, decimation=1, timeout=0, name="MyGraph")
        config.configure_trigger(sdk.datalogging.TriggerCondition.GreaterThan, [var1, 3.14159], position=0.75, hold_time=0)
        config.configure_xaxis(sdk.datalogging.XAxisType.MeasuredTime)
        axis1 = config.add_axis('Axis 1')
        axis2 = config.add_axis('Axis 2')
        config.add_signal(var1, axis1, name="MyVar1") 
        config.add_signal(var2, axis1, name="MyVar2")
        config.add_signal('/a/b/alias_rpv1000', axis2, name="MyAliasRPV1000")

        request = client.start_datalog(config)

        timeout = 60
        print(f"Embedded datalogger armed. Waiting for MyVar1>=3.14159...")
        try:
            request.wait_for_completion(timeout)    # Wait for the trigger condition to be fulfilled
        except sdk.exceptions.TimeoutException:
            print(f'Timed out while waiting')
        
        if request.completed:   # Will be False if timed out
            if request.is_success:
                acquisition = request.fetch_acquisition()
                filename = my_acquisition.csv
                acquisition.to_csv(filename)
                print(f"Acquisition [{acquisition.reference_id}] saved to CSV format in {filename}")
            else:
                print(f"The datalogging acquisition failed. Reason: {request.failure_reason}")

-----

Reading an acquisition after completion
---------------------------------------

A :class:`DataloggingAcquisition<scrutiny.core.datalogging.DataloggingAcquisition>` represent what the datalogger have captured. 
It contains multiple dataseries, some acquired by the device and some generated by the server (like the ideal time dataseries crafted from the sampling frequency).

The content of a dataseries is converted to double-precision floating point values so they can be more easily plotted or manipulated,

.. note:: 
    Double precision (64 bits) floating point values have a mantissa of 52 bits, therefore, only 64bits integers greater than 2^52 may lose precision during that conversion.
    The choice of auto-converting the values seemed to offer more advantages than disadvantage in the majority of real use cases.

Dataseries are tied to an axis. There can be a single X-Axis and multiple Y-Axis.

A :class:`DataloggingAcquisition<scrutiny.core.datalogging.DataloggingAcquisition>` can be obtained by calling either

- :meth:`DataloggingRequest.fetch_acquisition()<scrutiny.sdk.datalogging.DataloggingRequest.fetch_acquisition>` or :meth:`DataloggingRequest.wait_and_fetch()<scrutiny.sdk.datalogging.DataloggingRequest.wait_and_fetch>` 
- :meth:`ScrutinyClient.read_datalogging_acquisition<scrutiny.sdk.client.ScrutinyClient.read_datalogging_acquisition>` to read a past acquisition stored in the database.

Once a :class:`DataloggingAcquisition<scrutiny.core.datalogging.DataloggingAcquisition>` is obtained, 
the :meth:`DataloggingAcquisition.to_csv()<scrutiny.core.datalogging.DataloggingAcquisition.to_csv>` can be used to export the data

-----

.. autoclass:: scrutiny.core.datalogging.DataloggingAcquisition
    :members:
    :member-order: bysource
    :exclude-members: __init__, __new__

-----

.. autoclass:: scrutiny.core.datalogging.DataSeriesWithAxis
    :members:
    :member-order: bysource
    :exclude-members: __init__, __new__

-----

.. autoclass:: scrutiny.core.datalogging.DataSeries
    :members:
    :member-order: bysource
    :exclude-members: __init__, __new__


Fetching an acquisition from the database
-----------------------------------------

The server maintain a local sqlite database of all the acquisition captured. In most use case relevant for this SDK, a user will want
to download an acquisition that just got triggered, but it is also possible to browse the database and download 
past acquisitions (which is also possible through the :abbr:`CLI (Command Line Interface)`)

Each acquisition has a unique ID called the :attr:`reference_id<scrutiny.core.datalogging.DataloggingAcquisition.reference_id>`.
On can list the acquisition available by calling :meth:`ScrutinyClient.list_stored_datalogging_acquisitions<scrutiny.sdk.client.ScrutinyClient.list_stored_datalogging_acquisitions>`
and once the :attr:`reference_id<scrutiny.core.datalogging.DataloggingAcquisition.reference_id>` is known, it can be passed to 
:meth:`ScrutinyClient.read_datalogging_acquisitio()n<scrutiny.sdk.client.ScrutinyClient.read_datalogging_acquisition>`


.. automethod:: scrutiny.sdk.client.ScrutinyClient.list_stored_datalogging_acquisitions 

-----

.. automethod:: scrutiny.sdk.client.ScrutinyClient.read_datalogging_acquisition 

-----

.. autoclass:: scrutiny.sdk.datalogging.DataloggingStorageEntry
    :members:
    :member-order: bysource
    :exclude-members: __init__, __new__

Example
#######

.. code-block:: python

    with client.connect(hostname, port):
        entries = client.list_stored_datalogging_acquisitions()
        print(f"The server has {len(entries)} acquisition stored")
        for entry in entries:
            dt = entry.timestamp.strftime(r"%Y-%m-%d %H:%M:%S")
            print(f"[{entry.reference_id}] {entry.name} taken on {dt}")
        assert (len(entries) > 0, "Cannot fetch first datalogging acquisition")
        acquisition = client.read_datalogging_acquisition(entries[0].reference_id)   # Read the first one
        print(f"Acquisition {acquisition.name} [{acquisition.reference_id}] downloaded and has {len(acquisition.ydata)} signals on the Y-Axis. ")
        acquisition.to_csv("myfile.csv")

